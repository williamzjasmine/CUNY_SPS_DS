{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6309f619-8d15-49fd-a3b7-ef8cbb99ed5d",
   "metadata": {},
   "source": [
    "# Imports/Setup\n",
    "\n",
    "The cell below provides imports all the libraries and packages needed to run this notebook. Additionally, it defines a number of global variables used repeatedly throughout. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53fd1f84-bfb5-4e1c-9128-f623e19d80fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy import stats\n",
    "\n",
    "from qiskit.circuit.library import ZZFeatureMap, ZFeatureMap\n",
    "from qiskit.primitives import StatevectorSampler, Sampler\n",
    "from qiskit_machine_learning.algorithms import QSVC, PegasosQSVC\n",
    "from qiskit_aer import Aer\n",
    "\n",
    "\n",
    "from qiskit_machine_learning.state_fidelities import ComputeUncompute\n",
    "from qiskit_machine_learning.kernels import FidelityQuantumKernel\n",
    "from qiskit_machine_learning.utils import algorithm_globals\n",
    "\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler, PowerTransformer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, f1_score, make_scorer, confusion_matrix, precision_score, recall_score\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "from scipy.stats import shapiro, normaltest, boxcox, spearmanr, kendalltau\n",
    "from scipy.special import boxcox1p\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "fig_count = 0\n",
    "# !rm ../documents/figures/fig*\n",
    "\n",
    "figsize_x = 6\n",
    "figsize_y = 6\n",
    "\n",
    "algorithm_globals.random_seed = 19\n",
    "rs = 19\n",
    "\n",
    "sig = 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f5f435-259c-47e7-918a-5c23f4d0aa36",
   "metadata": {},
   "source": [
    "# Import Data\n",
    "\n",
    "The cell below reads in the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55f339b-edf2-4a1c-8781-2397f731a853",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/creditcard_2023.csv', usecols=lambda column: column != 'id')\n",
    "#df = df.sample(n=200, random_state=rs)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90653459-4dc9-4211-8370-d0ab4f982362",
   "metadata": {},
   "source": [
    "# Dataset Summary\n",
    "\n",
    "Provide a summary of the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0df706-efe6-4b6b-b621-9f5af881b53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d42ab9-6db8-44a9-b242-fc61e57d3498",
   "metadata": {},
   "source": [
    "The output elucidates that `df` contains 568,630 observations of 29 predictor variables (`V1`-`V28`, and `Class`) and one target variable, `Class`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd88f26-cec9-42bb-bef4-dda1a433101e",
   "metadata": {},
   "source": [
    "# Data Evaluation\n",
    "## Class Imbalance\n",
    "\n",
    "The cell below compares the observations in each class using histograms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9559135c-dd4a-4046-9f76-ba06b63ab150",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_count += 1\n",
    "plt.figure(figsize=(figsize_x, figsize_y))\n",
    "\n",
    "class_counts = df['Class'].value_counts()\n",
    "\n",
    "class_counts.plot(kind='bar')  # or use 'hist' for a histogram\n",
    "\n",
    "for i, value in enumerate(class_counts.values):\n",
    "    plt.text(i, value + 0.1, f'{value:,}', ha='center', va='bottom')\n",
    "    \n",
    "plt.xlabel('Class', fontweight='bold')\n",
    "plt.ylabel('Count of Transactions',fontweight='bold')\n",
    "plt.title('Transaction Count by Class', fontweight='bold')\n",
    "plt.ticklabel_format(style='sci', axis='y', scilimits=(0,0))\n",
    "\n",
    "plt.grid(axis='y')\n",
    "#plt.savefig(f'../documents/figures/fig_{fig_count}.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7154c0-1f2b-4732-be85-6dd7b976cc61",
   "metadata": {},
   "source": [
    "To make the dataset more realistic, the cell below drops drop positive (A.K.A fraudulent, 1) observations until they only make up 1% of the entire dataset. Removals are done at random."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7a91ae-d57f-4db2-a880-e22589df879e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fraud_prop = 0.01\n",
    "# fraud_size = int((fraud_prop * class_counts[0]) / (1 - fraud_prop))\n",
    "# num_removals = class_counts[1] - fraud_size\n",
    "\n",
    "# condition = df['Class'] == 1\n",
    "# rows_to_remove = df[condition].sample(n=num_removals, random_state=rs)\n",
    "# df = df.drop(rows_to_remove.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57d2f68-ee0a-4099-a67c-6f688c54bd40",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10000\n",
    "fraud_prop = 0.01\n",
    "fraud_size = int(n * fraud_prop)\n",
    "true_size = int(n * (1-fraud_prop))\n",
    "\n",
    "df_pt1 = df[df['Class'] == 1].sample(n=fraud_size, random_state=rs)\n",
    "df_pt2 = df[df['Class'] == 0].sample(n=true_size, random_state=rs)\n",
    "\n",
    "df = pd.concat([df_pt1, df_pt2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b84a000-c94c-4160-80b1-93297b628a46",
   "metadata": {},
   "source": [
    "The plot below checks to ensure an appropriate number of observations have been removed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09a696a-fe5c-4feb-bbde-6b32fe1549ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_count += 1\n",
    "plt.figure(figsize=(figsize_x, figsize_y))\n",
    "\n",
    "class_counts = df['Class'].value_counts()\n",
    "\n",
    "class_counts.plot(kind='bar')  # or use 'hist' for a histogram\n",
    "\n",
    "for i, value in enumerate(class_counts.values):\n",
    "    plt.text(i, value + 0.1, f'{value:,}', ha='center', va='bottom')\n",
    "    \n",
    "plt.xlabel('Class', fontweight='bold')\n",
    "plt.ylabel('Count of Transactions',fontweight='bold')\n",
    "plt.title('Transaction Count by Class', fontweight='bold')\n",
    "plt.ticklabel_format(style='sci', axis='y', scilimits=(0,0))\n",
    "\n",
    "plt.grid(axis='y')\n",
    "#plt.savefig(f'../documents/figures/fig_{fig_count}.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f74b1bb-fb63-46a3-b69d-52956d5ca65f",
   "metadata": {},
   "source": [
    "Before moving onto the next section, the cell below splits `df` into two new dataframes: \n",
    "\n",
    "* `df_X`: Contains only the predictors present in `df`.\n",
    "* `df_y`: Contains only the target variable in `df`: `Class`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1938a5-f3c5-437c-bcdb-782f3e7e1fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X = df.drop(['Class'], axis=1)\n",
    "df_y = df['Class']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8374f6-0c02-4486-afea-68e9e5d1548f",
   "metadata": {},
   "source": [
    "## Outliers\n",
    "\n",
    "Evaluating the presence of outliers is crucial to deciding the data pre-processing steps required for modelling. The cell below creates function that identifies the outliers in each column of a dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8e5b8f-e560-4745-9b99-3e81f7eb7996",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_outliers(df):\n",
    "    outlier_rows = []\n",
    "    for column in df.select_dtypes(include='number'):  # Only process numeric columns\n",
    "        Q1 = df[column].quantile(0.25)  # First quartile\n",
    "        Q3 = df[column].quantile(0.75)  # Third quartile\n",
    "        IQR = Q3 - Q1  # Interquartile range\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "\n",
    "        for i, value in enumerate(df[column].values):\n",
    "            if value < lower_bound or value > upper_bound:\n",
    "                outlier_rows.append([column, i, value])\n",
    "            \n",
    "    # Get unique rows with at least one outlier\n",
    "    return pd.DataFrame(outlier_rows, columns = ['column_name', 'row_num', 'value'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f8a2a8-7c02-42c6-92d8-b119fd0a767b",
   "metadata": {},
   "source": [
    "The `identify_outliers` function is used below to identify all outliers in `df`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e05d1f-ae7c-4d58-a02d-505da96b0d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_df = identify_outliers(df_X)\n",
    "outlier_df = (\n",
    "    outlier_df[['column_name', 'row_num']]\n",
    "    .groupby(by='column_name').count()\n",
    "    .sort_values(by='row_num')\n",
    "    .reset_index()\n",
    ")\n",
    "outlier_df.columns = ['column_name', 'num_outliers']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79893ec-6aa7-47c0-9d1e-780e8bb0d4dd",
   "metadata": {},
   "source": [
    "The data contained within `outlier_df` is presented in the plot below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c64ed8-625f-4b02-ab58-dc71bb0ae153",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_count += 1\n",
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "plt.bar(outlier_df['column_name'], outlier_df['num_outliers'])\n",
    "label_push = outlier_df['num_outliers'].mean() * 0.01\n",
    "\n",
    "for i, value in enumerate(outlier_df['num_outliers'].values):\n",
    "    \n",
    "    perc_outlier = (value / df.shape[0]) * 100\n",
    "    plt.text(i, value + label_push, f'{perc_outlier:.1f}%', ha='center', va='bottom', fontsize=6)\n",
    "    \n",
    "plt.tick_params(axis='x', which='major', labelsize=8)\n",
    "plt.xlabel('Variable Name', fontweight='bold')\n",
    "plt.ylabel('Number of Outliers',fontweight='bold')\n",
    "plt.title('Counts and Percentages of Outliers By Predictor', fontweight='bold')\n",
    "plt.ticklabel_format(style='sci', axis='y', scilimits=(0,0))\n",
    "\n",
    "label_height = outlier_df['num_outliers'].max() * .90\n",
    "plt.text(0, label_height, '* Percentage values represent the percentage of observations of each field that are outliers.', fontsize=8)\n",
    "\n",
    "plt.grid(axis='y')\n",
    "# #plt.savefig(f'../documents/figures/fig_{fig_count}.png')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73bf1fc-a168-4cb6-ab0d-2c2e059f2bda",
   "metadata": {},
   "source": [
    "Clearly, the dataframe contains a reasonable number of outliers in many of the fields. This will be one of the primary considerations when choosing the data pre-processing steps in the next section. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca56dc70-88ba-41be-9a10-7c4707ba17e9",
   "metadata": {},
   "source": [
    "## Distributions\n",
    "\n",
    "The shape of the distributions of each predictor is another consideration when determining the appropriate data pre-processing steps. They are plotted below using a boxplot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa08c5bf-0630-4c18-8924-574904870c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_count += 1\n",
    "plt.figure(figsize=(10,6))\n",
    "plt_df = df.drop(['Class', 'Amount'], axis=1)\n",
    "\n",
    "sns.boxplot(data=plt_df)\n",
    "plt.grid()\n",
    "plt.xlabel('Variable Name', fontweight='bold')\n",
    "plt.ylabel('Value', fontweight='bold')\n",
    "plt.title('Distributions of Fields V1-V28', fontweight='bold')\n",
    "plt.tick_params(axis='x', which='major', labelsize=8)\n",
    "#plt.savefig(f'../documents/figures/fig_{fig_count}.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a273d7f7-cd04-4ac1-9398-b8fd31409919",
   "metadata": {},
   "source": [
    "The many outliers make the distributions hard to see, but they can also be evaluated quantitatively to determine their shape. For instance, the cell below defines a function `evaluate_normality` that determines if each predictor variable exhibits a normal distribution using `scipy`'s `normaltest`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6a4e28-4ed3-4436-a66e-03e9913c090f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_normality(df):\n",
    "    results = []\n",
    "    for column in df.columns:\n",
    "        stat, p = normaltest(df[column])\n",
    "        normal = p > 0.05\n",
    "        results.append([column, stat, p, normal])\n",
    "                       \n",
    "\n",
    "    return pd.DataFrame(results, columns = ['variable_name', 'statistic', 'p_value', 'normal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062a62f6-3300-4dee-b749-d1dae8604ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_normality(df_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d174ca-1b94-46f3-9bc2-951a4080e2d1",
   "metadata": {},
   "source": [
    "The output above makes clear that none of the predictor variables can be considered to have a normal distribution. \n",
    "\n",
    "## Multicollinearity\n",
    "\n",
    "The last aspect of the data taken into consideration before apply any pre-processing transformation is its multicollinearity. The cell below produces a correlation matrix of all the predictor fields, which checks the correlation of all pairs of predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9737c21d-8e3b-4fc3-a26c-b5c88c9c71b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = df_X.corr()\n",
    "sns.heatmap(correlation_matrix, cmap='coolwarm', fmt=\".2f\", square=True)\n",
    "print(max(correlation_matrix))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a8aadb-6bac-4bcb-a710-94aedc0fa783",
   "metadata": {},
   "source": [
    "The minimum and maximum correlation values are also displayed below: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309b98dd-3d88-466d-9591-ef570f460d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = correlation_matrix.replace(1, 0)\n",
    "\n",
    "max_corr_value = correlation_matrix.select_dtypes(include='number').max().max()\n",
    "min_corr_value = correlation_matrix.select_dtypes(include='number').min().min()\n",
    "\n",
    "print(f'Minimum correlation value: {min_corr_value}')\n",
    "print(f'Maximum correlation value: {max_corr_value}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f1af45-f725-4b33-a8a8-239712077b2c",
   "metadata": {},
   "source": [
    "The output above coupled with the results of the correlation matrix provide strong evidence that no pair of predictor variables maintain a troublesome degree of correlation. \n",
    "\n",
    "# Data Pre-Processing\n",
    "\n",
    "Based on the results of the previous section, there are two facets of the data that need to be addressed:\n",
    "\n",
    "1. A large number of outliers present within many predictors.\n",
    "2. Non-normal distributions for all predictors. \n",
    "\n",
    "There is no reason to believe the outliers are due to error, and should likely continue to be included in the dataset. However, given their quantity and scale, these outliers can have their influence limited by applying Winsorization, in which outliers are \"pulled in\" by capping extreme values to a specified percentile range. \n",
    "\n",
    "To address the non-normal (skewed) distributions of the predictors, we can perform a power transformation that will have the effect of smoothing the variance over the range of the distribution (reducing heteroscedasticity). This kind of transformation typically supports normalization. Box-Cox and Yeo-Johnson transformations are the most common approaches, but the latter will be applied in this case since the former only works for values $>0$. \n",
    "\n",
    "To prevent data leakage, these transformations will be fitted exclusively on a training dataset, and the resultant parameters will then be applied to transform the data.\n",
    "\n",
    "First the cell below splits the data into testing and training matrices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779bd946-4eeb-41f3-868e-e601d73e880d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_X.values\n",
    "y = df_y.values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.25, random_state=rs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcaf7335-667e-4a0c-b87f-c9a90c70bfa0",
   "metadata": {},
   "source": [
    "Next, the cell below defines a function that can apply the windsorization transformation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e33163a-aa93-4e2b-8d98-8c16ebbbef18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_winsorization(train_matrix, test_matrix, limits=(0.05, 0.95)):\n",
    "    \"\"\"\n",
    "    Apply Winsorization to all columns in training and test matrices.\n",
    "\n",
    "    Args:\n",
    "        train_matrix (np.ndarray): Training data matrix.\n",
    "        test_matrix (np.ndarray): Test data matrix.\n",
    "        limits (tuple): Quantile limits for Winsorization (default is (0.05, 0.95)).\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray, np.ndarray: Transformed training and test matrices.\n",
    "    \"\"\"\n",
    "    train_matrix = train_matrix.copy()\n",
    "    test_matrix = test_matrix.copy()\n",
    "\n",
    "    for col in range(train_matrix.shape[1]):  # Loop over all columns\n",
    "        lower, upper = np.quantile(train_matrix[:, col], limits)\n",
    "        train_matrix[:, col] = np.clip(train_matrix[:, col], lower, upper)\n",
    "        test_matrix[:, col] = np.clip(test_matrix[:, col], lower, upper)\n",
    "    \n",
    "    return train_matrix, test_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99889782-ca80-4f90-b21a-b593a2f702d4",
   "metadata": {},
   "source": [
    "The training and testing data are transformed below using the `apply_windsorization` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225d2eac-0b30-46f1-a717-a692134638b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = apply_winsorization(X_train, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63371ebe-f096-4038-a568-adad7dbf7554",
   "metadata": {},
   "source": [
    "Next, the cell below applies the Yeo-Johnson transformation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a41859-c6c0-4e6f-a03e-19db2867e981",
   "metadata": {},
   "outputs": [],
   "source": [
    "yj = PowerTransformer(method='yeo-johnson')\n",
    "\n",
    "X_train = yj.fit_transform(X_train)\n",
    "X_test = yj.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a044223-b95f-461b-96e1-15b719ca15a6",
   "metadata": {},
   "source": [
    "The final pre-processing step is to scale the data appropriately. Given that the data was not originally considered normal, standard scaling (in which $\\mu$=0 and $\\sigma=1$ is not appropriate. Furthermore, min-max scaling (in which all fields are scaled to be between 0 and 1) is sensitive to outliers, which excludes it as a choice in this case. Robust scaling is a common choice when dealing with data with outliers, since it works by centering the data it each field around its median value and then scaling according to its IQR. As such, this was the scaling option implemented: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d059a90-ca48-4059-9054-5f6bd5426a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = RobustScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8b2a7f-1f7d-4a46-a9ff-f429eb6c9270",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X_pp = pd.DataFrame(np.vstack((X_train, X_test)), columns=df_X.columns)\n",
    "df_y_pp = pd.Series(np.concatenate([y_train, y_test]), name=df_y.name)\n",
    "df_pp = pd.concat([df_X_pp, df_y_pp], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73121abb-d54e-42f8-a24f-fd7fe0f46eb8",
   "metadata": {},
   "source": [
    "The result of the scaling is shown in the following plot: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7715112-6398-42b5-8c9b-0ab6d97868a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_count += 1\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "sns.boxplot(data=df_X_pp)\n",
    "plt.grid()\n",
    "plt.xlabel('Variable Name', fontweight='bold')\n",
    "plt.ylabel('Value', fontweight='bold')\n",
    "plt.title('Distributions of All Fields (Post Pre-Processing)', fontweight='bold')\n",
    "plt.xticks(rotation=45)\n",
    "#plt.savefig(f'../documents/figures/fig_{fig_count}.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1c8555-8fef-40d9-8056-ecbb71a6c17c",
   "metadata": {},
   "source": [
    "It is clear that the result of the pre-processing steps resulted in a significantly more interpretable dataset. The ranges of each field are similar and outliers now only exist in two (instead of all) fields: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed435b6-5f3f-4750-860a-5240e1ddbe6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_df = identify_outliers(df_X_pp)\n",
    "outlier_df = (\n",
    "    outlier_df[['column_name', 'row_num']]\n",
    "    .groupby(by='column_name').count()\n",
    "    .sort_values(by='row_num')\n",
    "    .reset_index()\n",
    ")\n",
    "outlier_df.columns = ['column_name', 'num_outliers']\n",
    "outlier_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb14263e-d284-4a9d-9e51-27cd13460f7b",
   "metadata": {},
   "source": [
    "Unfortunately, the data is still not considered to be normal, meaning that further pre-processing transformations such as PCA would likely not be as effective. However, multicollinearity was deemed earlier not to be a significant concern in this dataset, meaning there is not likely a great need for dimensionality reduction regardless. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41bb976a-38f5-44aa-b4d9-b58cd6570a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_normality(df_X_pp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f84c45-4479-45b6-8eea-4d37ec82629e",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis\n",
    "\n",
    "The cell below evaluates which predictors might be most important to the model by performing $t$-tests of the means of each predictor variable separated by class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d9df25-c53c-4722-9c6a-a37da38753b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class0 = df_pp[df_pp['Class'] == 0]\n",
    "df_class1 = df_pp[df_pp['Class'] == 1]\n",
    "\n",
    "p_vals = []\n",
    "for col in df_X.columns:\n",
    "    \n",
    "    group1 = df_class0[col]\n",
    "    group2 = df_class1[col]\n",
    "    \n",
    "    t_statistic, p_value = stats.ttest_ind(group1, group2, equal_var=False)\n",
    "    \n",
    "    p_vals.append(p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff79908-08a5-4b13-b828-9126a30d7bd1",
   "metadata": {},
   "source": [
    "The results of these t-tests can be visualized below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a824a319-c713-4698-be45-1e5060be61e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_count += 1\n",
    "plt.figure(figsize=(10, figsize_y))\n",
    "\n",
    "xs = np.arange(0,len(p_vals))\n",
    "plt.scatter(xs, p_vals, label='$t$-test $p$-values')\n",
    "plt.axhline(sig, color='black', ls='--', label='Significance Barrier')\n",
    "plt.axhspan(0, sig, color='green', alpha=0.2)\n",
    "plt.axhspan(sig, 1, color='red', alpha=0.2)\n",
    "plt.xticks(xs, df_X.columns)\n",
    "plt.xlabel('Variable Name', fontweight='bold')\n",
    "plt.ylabel('$p$-value', fontweight='bold')\n",
    "plt.title('$t$-test Results When Comparing the Means of Each Predictor By Class', fontweight='bold')\n",
    "plt.ylim(-0.05,1)\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "#plt.savefig(f'../documents/figures/fig_{fig_count}.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb090e7-78aa-4bd1-ae35-f43e06db54f5",
   "metadata": {},
   "source": [
    "Most of the variables exhibit statistically significant differences when comparing the means of the observations in each class. The cells below provide histograms of two of these predictors as examples, highlighting the difference in distribution when split by class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125f803f-34f4-44a2-a9cd-86973ee3ddb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_count += 1\n",
    "plt.figure(figsize=(figsize_x, figsize_y))\n",
    "\n",
    "group1 = df_class0['V1']\n",
    "group2 = df_class1['V1']\n",
    "\n",
    "plt.hist(group1, bins=15, alpha=0.5, density=True, label='Class 0')\n",
    "plt.hist(group2, bins=15, alpha=0.5, density=True, label='Class 1')\n",
    "\n",
    "plt.title('Distribution Comparison of V1 Feature', fontweight='bold')\n",
    "plt.grid()\n",
    "plt.xlabel('Value', fontweight='bold')\n",
    "plt.ylabel('Probability Density', fontweight='bold')\n",
    "#plt.savefig(f'../documents/figures/fig_{fig_count}.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8a62ea-a3c7-454e-8757-31af54909cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_count += 1\n",
    "plt.figure(figsize=(figsize_x, figsize_y))\n",
    "\n",
    "group1 = df_class0['V4']\n",
    "group2 = df_class1['V4']\n",
    "\n",
    "plt.hist(group1, bins=15, alpha=0.5, density=True, label='Class 0')\n",
    "plt.hist(group2, bins=15, alpha=0.5, density=True, label='Class 1')\n",
    "\n",
    "plt.title('Distribution Comparison of V4 Feature', fontweight='bold')\n",
    "plt.grid()\n",
    "plt.xlabel('Value', fontweight='bold')\n",
    "plt.ylabel('Probability Density', fontweight='bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b05a56c-46e4-4182-bbde-31791a7a3c71",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e92712-87e3-4cbb-8ce1-9cd2fddc5f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA()\n",
    "pca.fit(X_train)\n",
    "\n",
    "explained_variance = pca.explained_variance_ratio_\n",
    "cumulative_variance = np.cumsum(explained_variance)\n",
    "n_components_to_keep = np.argmax(cumulative_variance >= 0.95) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dcd5c9a-f15b-4c8e-a2c3-8c9031f66b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(range(1, len(explained_variance) + 1), cumulative_variance, marker='o', linestyle='--', label='Cumulative Explained Variance')\n",
    "plt.bar(range(1, len(explained_variance) + 1), explained_variance, alpha=0.6, label='Individual Explained Variance')\n",
    "\n",
    "plt.axhline(y=0.95, color='r', linestyle='--', label='95% Variance Threshold')\n",
    "plt.title('Explained Variance vs. Number of Components', fontweight='bold')\n",
    "plt.xlabel('Number of Components', fontweight='bold')\n",
    "plt.ylabel('Explained Variance', fontweight='bold')\n",
    "plt.xticks(range(1, len(explained_variance) + 1))\n",
    "plt.legend(loc='best')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e11e3a-3b16-443d-899d-88eb487a1b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pca = PCA(n_components = n_components_to_keep)\n",
    "# X_train = pca.fit_transform(X_train)\n",
    "# X_test = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27e4e64-deaf-473d-8bc3-92bcddf540c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig_count += 1\n",
    "# plt.figure(figsize=(figsize_x, figsize_y))\n",
    "\n",
    "# class_counts = pd.Series(y_train).value_counts()\n",
    "\n",
    "# class_counts.plot(kind='bar')  # or use 'hist' for a histogram\n",
    "\n",
    "# for i, value in enumerate(class_counts.values):\n",
    "#     plt.text(i, value + 0.1, f'{value:,}', ha='center', va='bottom')\n",
    "    \n",
    "# plt.xlabel('Class', fontweight='bold')\n",
    "# plt.ylabel('Count of Transactions',fontweight='bold')\n",
    "# plt.title('Transaction Count by Class', fontweight='bold')\n",
    "# plt.ticklabel_format(style='sci', axis='y', scilimits=(0,0))\n",
    "\n",
    "# plt.grid(axis='y')\n",
    "# #plt.savefig(f'../documents/figures/fig_{fig_count}.png')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce5029a-f0f2-4edd-afea-899af59bca9b",
   "metadata": {},
   "source": [
    "# Classical Machine Learning \n",
    "## SVM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459c87f3-1bd8-4916-9fd5-29efc1582601",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC(class_weight='balanced', random_state=rs) \n",
    "\n",
    "# Define the hyperparameter grid\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'gamma': [1, 0.1, 0.01],\n",
    "    'kernel': ['linear', 'rbf']\n",
    "}\n",
    "\n",
    "# Perform grid search\n",
    "scoring_fcn = make_scorer(f1_score, pos_label=1)\n",
    "grid_search = GridSearchCV(estimator=svm, param_grid=param_grid, cv=3, scoring=scoring_fcn, verbose=2)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print best parameters and evaluate on the test set\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "best_svm_model = grid_search.best_estimator_\n",
    "y_pred = best_svm_model.predict(X_test)\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baae0db9-d4f6-4c23-ac51-6c408f5a7698",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = permutation_importance(best_svm_model, X_test, y_test, n_repeats=10)\n",
    "importances = result.importances_mean\n",
    "importance_df_svm = pd.DataFrame({'variable_name': df_X_pp.columns, 'permutation_importance': importances})\n",
    "importance_df_svm = importance_df_svm.sort_values(by='permutation_importance', ascending=False).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2007f2ee-ea65-420e-ae14-27a5a2e9dd2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,figsize_y))\n",
    "\n",
    "plt.bar(importance_df_svm['variable_name'], importance_df_svm['permutation_importance'])\n",
    "\n",
    "plt.title('Permutation Importance (Classical SVM Model)', fontweight='bold')\n",
    "plt.xlabel('Variable Name', fontweight='bold')\n",
    "plt.ylabel('Permutation Importance', fontweight='bold')\n",
    "plt.xticks(rotation=45, fontsize = 7)\n",
    "\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da6b7f1-424d-4466-84ff-e56ccb2a1ceb",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc880d58-7c1b-4236-b60c-89a600326791",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(class_weight='balanced', random_state=rs)\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [10, 20],\n",
    "    'min_samples_split': [5, 10],\n",
    "    'min_samples_leaf': [1, 2]\n",
    "}\n",
    "\n",
    "# Perform grid search\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=3, scoring=scoring_fcn, verbose=2)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print best parameters and evaluate on the test set\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "best_rf_model = grid_search.best_estimator_\n",
    "y_pred = best_rf_model.predict(X_test)\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12aba71-3ecf-45e6-aa36-f1b514f2895a",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = best_rf_model.feature_importances_\n",
    "\n",
    "importance_df_rf = pd.DataFrame({'variable_name': df_X_pp.columns, 'feature_importance': feature_importances})\n",
    "importance_df_rf = importance_df_rf.sort_values(by='feature_importance', ascending=False).reset_index(drop=True)\n",
    "\n",
    "plt.figure(figsize=(10, figsize_y))\n",
    "plt.bar(importance_df_rf['variable_name'], importance_df_rf['feature_importance'])\n",
    "plt.title('Feature Importances (Classical RF Model)', fontweight='bold')\n",
    "plt.xlabel('Variable Name', fontweight='bold')\n",
    "plt.ylabel('Feature Importance', fontweight='bold')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692b437b-45a8-41df-9cce-b7844b0dcae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_ranks = []\n",
    "\n",
    "for column in df_X_pp.columns:\n",
    "    rank_rf = importance_df_rf[importance_df_rf['variable_name'] == column].index.item()\n",
    "    rank_svm = importance_df_svm[importance_df_svm['variable_name'] == column].index.item()\n",
    "    feature_ranks.append([column, rank_rf, rank_svm])\n",
    "\n",
    "feature_ranks_df = pd.DataFrame(feature_ranks, columns=['variable_name', 'rf_importance', 'svm_importance'])\n",
    "rho, p_val = spearmanr(feature_ranks_df['rf_importance'], feature_ranks_df['svm_importance'])\n",
    "tau, p_val = kendalltau(feature_ranks_df['rf_importance'], feature_ranks_df['svm_importance'])\n",
    "rho"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea51c7a7-943c-47b8-b3e0-45197aa6081e",
   "metadata": {},
   "source": [
    "# Quantum Algorithm Evaluation\n",
    "## Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971ab96b-21af-4942-82f5-6b530e6a7bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# n = 1000\n",
    "# fraud_prop = 0.10\n",
    "# fraud_size = int(n * fraud_prop)\n",
    "# true_size = int(n * (1-fraud_prop))\n",
    "\n",
    "# q_df_pt1 = df_pp[df_pp['Class'] == 1].sample(n=fraud_size, random_state=rs)\n",
    "# q_df_pt2 = df_pp[df_pp['Class'] == 0].sample(n=true_size, random_state=rs)\n",
    "\n",
    "# q_df = pd.concat([q_df_pt1, q_df_pt2], ignore_index=True)\n",
    "# q_X = q_df.drop(columns='Class').values\n",
    "# q_y = q_df['Class'].values\n",
    "\n",
    "q_X_train, q_X_test, q_y_train, q_y_test = train_test_split(X, y, stratify=y, test_size=0.25, random_state=rs)\n",
    "\n",
    "\n",
    "\n",
    "smote = SMOTE(random_state=rs, k_neighbors=3)\n",
    "q_X_train, q_y_train = smote.fit_resample(q_X_train, q_y_train)\n",
    "\n",
    "q_train = pd.DataFrame(np.hstack((q_X_train, q_y_train.reshape(-1,1))), columns=df_pp.columns)\n",
    "q_test = pd.DataFrame(np.hstack((q_X_test, q_y_test.reshape(-1,1))), columns=df_pp.columns)\n",
    "\n",
    "n = 50\n",
    "q_train_df_pt1 = q_train[q_train['Class'] == 1].sample(n=n, random_state=rs)\n",
    "q_train_df_pt2 = q_train[q_train['Class'] == 0].sample(n=n, random_state=rs)\n",
    "\n",
    "n = 25\n",
    "q_test_df_pt1 = q_test[q_test['Class'] == 1].sample(n=n, random_state=rs)\n",
    "q_test_df_pt2 = q_test[q_test['Class'] == 0].sample(n=n, random_state=rs)\n",
    "\n",
    "q_train = pd.concat([q_train_df_pt1, q_train_df_pt2], ignore_index=True)\n",
    "q_test = pd.concat([q_test_df_pt1, q_test_df_pt2], ignore_index=True)\n",
    "\n",
    "q_X_train = q_train.drop(columns='Class').values\n",
    "q_y_train = q_train['Class'].values\n",
    "q_X_test = q_test.drop(columns='Class').values\n",
    "q_y_test = q_test['Class'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee4b77a-6c8e-40ce-a963-edac1ff18838",
   "metadata": {},
   "source": [
    "## QSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72567f06-ccf8-4e5f-b45f-6ddc3f576616",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_qsvc(X_train, y_train, reps, entanglement):\n",
    "    \n",
    "    feature_map = ZZFeatureMap(feature_dimension=X_train.shape[1], reps=reps, entanglement=entanglement)\n",
    "    sampler = StatevectorSampler()\n",
    "    fidelity = ComputeUncompute(sampler=sampler, num_virtual_qubits=X_train.shape[1])\n",
    "    qkernel = FidelityQuantumKernel(fidelity=fidelity, feature_map=feature_map)\n",
    "    qsvc = QSVC(quantum_kernel=qkernel)\n",
    "    sample_weights = compute_sample_weight(class_weight=\"balanced\", y=y_train)\n",
    "\n",
    "    start_time = time.time()\n",
    "    qsvc.fit(X_train, y_train, sample_weight=sample_weights) \n",
    "    end_time = time.time()\n",
    "    execution_time = end_time - start_time\n",
    "    \n",
    "    return qsvc, execution_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb913444-1a2a-4634-802d-26c1fb8b8103",
   "metadata": {},
   "outputs": [],
   "source": [
    "# qsvc, runtime = fit_qsvc(X_train_tmp, q_y_train, 1, 'linear')\n",
    "# y_pred = qsvc.predict(X_test_tmp)\n",
    "# report = classification_report(q_y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3dce1a-3cf2-485c-a679-676d5e1d3c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_qsvc(qubits_range, entanglement_types, reps_range, importance_df, X_train, X_test, y_train, y_test):\n",
    "\n",
    "    results = []\n",
    "    for num_qubits in qubits_range:\n",
    "            \n",
    "        feature_names = importance_df['variable_name'].values[:num_qubits]\n",
    "        feature_indices = df_X_pp.columns.get_indexer(feature_names)\n",
    "        X_train_tmp = X_train[:, feature_indices]\n",
    "        X_test_tmp = X_test[:, feature_indices]\n",
    "\n",
    "        for entanglement_type in entanglement_types:\n",
    "            for reps in reps_range:\n",
    "\n",
    "                print('Running QSVC algorithm with the following parameters...')\n",
    "                print(f'num_qubits={num_qubits}, entanglement_type={entanglement_type}, reps={reps}')\n",
    "                \n",
    "                qsvc, runtime = fit_qsvc(X_train_tmp, q_y_train, reps, entanglement_type) \n",
    "                y_pred =  qsvc.predict(X_test_tmp)\n",
    "                f1_class1 = f1_score(y_test, y_pred, pos_label=1)\n",
    "                f1_class0 = f1_score(y_test, y_pred, pos_label=0)\n",
    "                precision_class1 = precision_score(y_test, y_pred, pos_label=1)\n",
    "                precision_class0 = precision_score(y_test, y_pred, pos_label=0)\n",
    "                recall_class1 = recall_score(y_test, y_pred, pos_label=1)\n",
    "                recall_class0 = recall_score(y_test, y_pred, pos_label=0)\n",
    "                accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "                results.append([num_qubits, entanglement_type, reps, runtime, f1_class1, f1_class0, precision_class1,\n",
    "                                precision_class0, recall_class1, recall_class0, accuracy])\n",
    "\n",
    "\n",
    "    column_names = ['num_quibits', 'entanglement_type', 'reps', 'runtime', 'f1_class1', 'f1_class0', 'precision_class1',\n",
    "                    'precision_class0', 'recall_class1', 'recall_class0', 'accuracy']\n",
    "                \n",
    "    return pd.DataFrame(results, columns=column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c323886-e2ff-466a-9186-d24ac40c7845",
   "metadata": {},
   "outputs": [],
   "source": [
    "qubits_range = list(range(2,10))\n",
    "entanglement_types = ['linear', 'circular', 'full']\n",
    "reps_range = [1,2,3]\n",
    "\n",
    "qsvc_results = evaluate_qsvc(qubits_range, \n",
    "                             entanglement_types, \n",
    "                             reps_range, \n",
    "                             importance_df_svm, \n",
    "                             q_X_train, q_X_test, q_y_train, q_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dcf0749-b5ce-46b8-8795-987d83d45330",
   "metadata": {},
   "outputs": [],
   "source": [
    "qsvc_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c081aa24-eef9-401d-ade6-c859eee2582d",
   "metadata": {},
   "source": [
    "## Pegasos QSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8ab70a-4c4c-4d05-9184-f13590982a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_pegasos_qsvc(X_train, y_train, reps, C, tau):\n",
    "    \n",
    "    feature_map = ZFeatureMap(feature_dimension=q_X_train.shape[1], reps=1)\n",
    "    qkernel = FidelityQuantumKernel(feature_map=feature_map)\n",
    "    pegasos_qsvc = PegasosQSVC(quantum_kernel=qkernel, C=C, num_steps=tau)\n",
    "\n",
    "    start_time = time.time()\n",
    "    pegasos_qsvc.fit(q_X_train, y_train) \n",
    "    end_time = time.time()\n",
    "    fit_time = end_time - start_time\n",
    "    \n",
    "    return pegasos_qsvc, execution_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd028e73-2c81-4298-a1c5-a1d07b7e82ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "pegasos_qsvc, runtime = fit_pegasos_qsvc(q_X_train, y_train, 1, 1000, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f874f34-11d2-4783-a082-1f93430fa6ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def evaluate_pegasos_qsvc(qubits_range, reps_range, C_range, tau_range, importance_df, X_train, X_test, y_train, y_test):\n",
    "\n",
    "    results = []\n",
    "    for num_qubits in qubits_range:\n",
    "            \n",
    "        feature_names = importance_df['variable_name'].values[:num_qubits]\n",
    "        feature_indices = df_X_pp.columns.get_indexer(feature_names)\n",
    "        X_train_tmp = X_train[:, feature_indices]\n",
    "        X_test_tmp = X_test[:, feature_indices]\n",
    "\n",
    "        for reps in reps_range:        \n",
    "            for C in C_range:\n",
    "                for tau in tau_range:\n",
    "\n",
    "                    print('Running PegasosQSVC algorithm with the following parameters...')\n",
    "                    print(f'num_qubits={num_qubits}, reps={reps}, C={C}, tau={tau}')\n",
    "                \n",
    "                    pegasos_qsvc, runtime = fit_pegasos_qsvc(X_train_tmp, q_y_train, C, tau) \n",
    "                    y_pred =  pegasos_qsvc.predict(X_test_tmp)\n",
    "                    f1_class1 = f1_score(y_test, y_pred, pos_label=1)\n",
    "                    f1_class0 = f1_score(y_test, y_pred, pos_label=0)\n",
    "                    precision_class1 = precision_score(y_test, y_pred, pos_label=1)\n",
    "                    precision_class0 = precision_score(y_test, y_pred, pos_label=0)\n",
    "                    recall_class1 = recall_score(y_test, y_pred, pos_label=1)\n",
    "                    recall_class0 = recall_score(y_test, y_pred, pos_label=0)\n",
    "                    accuracy = accuracy_score(y_test, y_pred)\n",
    "        \n",
    "                    results.append([num_qubits, reps, C, tau, runtime, f1_class1, f1_class0, precision_class1,\n",
    "                                    precision_class0, recall_class1, recall_class0, accuracy])\n",
    "\n",
    "\n",
    "    column_names = ['num_quibits', 'reps', 'C', 'tau', 'runtime', 'f1_class1', 'f1_class0', 'precision_class1',\n",
    "                    'precision_class0', 'recall_class1', 'recall_class0', 'accuracy']\n",
    "                \n",
    "    return pd.DataFrame(results, columns=column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76466067-4bec-4140-b995-937976b9d802",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
